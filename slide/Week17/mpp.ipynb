{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T02:15:43.144050Z",
     "start_time": "2019-05-21T02:15:43.055066Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import zeros, mean\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import pylab\n",
    "from pylab import rcParams\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler #RobustScaler\n",
    "#from sklearn import linear_model, kernel_ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "import tabulate\n",
    "\n",
    "from mtds.reader import read_vasp_from_dir\n",
    "from mtds.helper import  filter_element_or, get_row_group_density_vec, aggregate_data, row_group_limits, show_correlations\n",
    "from mtds.plots import display_cv, data4plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T02:05:41.256317Z",
     "start_time": "2019-05-21T02:05:36.400058Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read local data of raw (downloaded) VASP format(*.vasp).\n",
    "PATH_BASE = os.path.join(os.getcwd(), 'database')\n",
    "path_bin = os.path.join(PATH_BASE)\n",
    "path_bin_all = os.path.join(PATH_BASE)\n",
    "\n",
    "# bin_mts and bin_mts_all are both list of dictionaries\n",
    "bin_mts = read_vasp_from_dir(path_bin)          \n",
    "bin_mts_all = read_vasp_from_dir(path_bin_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T02:05:43.810828Z",
     "start_time": "2019-05-21T02:05:43.799835Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"\"\"Filter Materials.\"\"\"\n",
    "def mt_filter(mt):\n",
    "    #\"\"\"Use this to filter data you don't need.\"\"\"\n",
    "    return mt['Tensile_modulus']\n",
    "\n",
    "def get_targets_mine(mt):\n",
    "    #\"\"\"Return user-defined target.\"\"\"\n",
    "    return mt[MyTarget]*units #  'Specific_heat_capacity' 'Thermal_conductivity' 'Tensile_modulus' 'Shear_modulus' 'Thermal_expansion_coefficient'\n",
    "\n",
    "def get_specific_features_mine(mt):\n",
    "    #\"\"\"Return specific features.\"\"\"\n",
    "    target_features = ['Poisson_ratio', 'Tensile_strength,_ultimate', 'Tensile_strength,_yield','Density']\n",
    "    features = zeros(len(target_features)) \n",
    "    for i in range(len(target_features)):\n",
    "        features[i] = mt[target_features[i]]   \n",
    "    return features\n",
    "\n",
    "def get_features_mine(mt):\n",
    "    # Get the boundary of rows and groups of periodic table.\n",
    "    rg_limits = row_group_limits()\n",
    "    rg_features = get_row_group_density_vec(mt, rg_limits)\n",
    "    spec_features = get_specific_features_mine(mt)\n",
    "    return np.concatenate((rg_features, spec_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T02:06:52.484780Z",
     "start_time": "2019-05-21T02:06:52.457795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of All Materials:711\n",
      "Number of USED Materials:711\n",
      "Number of Training Materials: 639 [Filtered]\n",
      "Number of Testing  Materials: 72 [Filtered]\n"
     ]
    }
   ],
   "source": [
    "#\"\"\"return mt # use all available.\"\"\"\n",
    "mts_all = bin_mts_all\n",
    "print('Number of All Materials:{}'.format(len(mts_all)))\n",
    "\n",
    "#\"\"\"Filter materials for some condition.\"\"\"\n",
    "mts_used = [mt for mt in mts_all if mt_filter(mt)]\n",
    "print('Number of USED Materials:{}'.format(len(mts_used)))\n",
    "\n",
    "mts_train, mts_test = train_test_split(bin_mts, test_size=0.10, random_state=0)\n",
    "print('Number of Training Materials: {} [Filtered]'.format(len(mts_train)))\n",
    "print('Number of Testing  Materials: {} [Filtered]'.format(len(mts_test)))\n",
    "\n",
    "\n",
    "#\"\"\"Define functions for fetching features and targets.\"\"\"\n",
    "units = 1e-9\n",
    "MyTarget = 'Shear_modulus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T02:15:24.859252Z",
     "start_time": "2019-05-21T02:15:24.846261Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"\"\"A shortcut for feature target pairing.\"\"\"\n",
    "collecting = lambda x, y, z: [[y(mt) for mt in x], [z(mt) for mt in x]]\n",
    "#features_train, targets_train = collecting(mts_train, get_features_mine, get_targets_mine)\n",
    "#features_test, targets_test = collecting(mts_test, get_features_mine, get_targets_mine)\n",
    "features_train, targets_train = collecting(mts_train, get_specific_features_mine, get_targets_mine)\n",
    "features_test, targets_test = collecting(mts_test, get_specific_features_mine, get_targets_mine)\n",
    "#print('Feature Vector Length: {}'.format(len(features_train[0])))\n",
    "#print('Train - # of features: {}, targets: {}'.format(len(features_train), len(targets_train)))\n",
    "#print('Test  - # of features: {}, targets: {}'.format(len(features_test), len(targets_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-21T02:15:48.982568Z",
     "start_time": "2019-05-21T02:15:48.950588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Poisson_ratio    Tensile_strength,_ultimate    Tensile_strength,_yield    Density    Target\n",
      "---------------  ----------------------------  -------------------------  ---------  --------\n",
      "       0.326465                   6.52867e+08                5.07785e+08    7829.9   77.9244\n",
      "       0.319468                   3.70563e+08                3.70563e+08    1539.71  18.2748\n",
      "       0.289957                   1.09675e+09                9.82166e+08    7849.84  80.4239\n",
      "       0.289957                   1.07664e+09                9.32416e+08    7849.84  80.4239\n",
      "       0.379868                   5.37192e+08                3.97995e+08    9024.69  39.6863\n",
      "       0.356685                   2.41999e+09                2.41999e+09    1559.97   5.44977\n",
      "       0.299833                   3.15278e+08                2.33666e+08    1799.97  16.9706\n",
      "       0.336667                   2.78482e+08                2.53367e+08    2712.6   26.6583\n",
      "       0.357071                   1.75083e+08                9.54358e+07    1801.94  17.4304\n",
      "       0.336667                   5.58248e+08                4.98554e+08    2819.96  27.6837\n",
      "       0.289957                   5.96992e+08                3.505e+08      7849.84  80.4239\n",
      "       0.289957                   8.92721e+08                7.60805e+08    7849.84  80.4239\n",
      "       0.264575                   3.34111e+08                3.04959e+08    2236.97  25.3772\n",
      "       0.289828                   1.402e+09                  9.995e+08      8199.39  79.8436\n",
      "       0.329962                   3.30088e+08                2.7965e+08     2749.84  26.4575\n",
      "       0.336667                   2.46008e+08                1.09672e+08    2657.24  27.6837\n",
      "       0.289957                   1.08444e+09                7.88194e+08    7849.84  82.4621\n",
      "       0.275455                   1.08706e+09                9.41978e+08    7833.31  90.2282\n",
      "       0.299833                   7.81823e+08                5.57602e+08    7824.99  77.1854\n",
      "       0.25923                    1.23653e+08                1.23653e+08    2705     41.0999\n",
      "       0.339411                   2.89637e+08                2.7965e+08     2699.83  26.9815\n",
      "       0.275455                   1.14488e+09                9.15743e+08    8248.51  51.266\n",
      "       0.336667                   2.82804e+08                1.1679e+08     2657.24  24.9199\n",
      "       0.314643                   9.40638e+08                7.82576e+08    7749.36  79.8436\n",
      "       0.336667                   4.2789e+08                 3.03737e+08    2767.96  28.709\n",
      "       0.189737                   6.54981e+08                6.54981e+08    1822.21  28.3901\n",
      "       0.329934                   1.12751e+09                9.9077e+08     4499.78  45.9856\n",
      "       0.336667                   4.93067e+08                4.20526e+08    2850.99  28.709\n",
      "       0.338674                   1.01705e+09                8.4573e+08     4428.73  42.4264\n",
      "       0.336667                   2.97522e+08                1.30363e+08    2657.24  27.6837\n",
      "       0.289957                   1.20127e+09                1.13142e+09    7849.84  79.9437\n",
      "       0.299958                   1.36635e+09                1.16618e+09    7825     76.9766\n",
      "       0.285657                   1.26894e+09                1.1964e+09     7722.6   77.9244\n",
      "       0.284956                   3.45106e+07                3.45106e+07    2514.88  25.9572\n",
      "       0.326465                   1.59484e+09                1.34148e+09    7833.31  77.9244\n",
      "       0.289957                   4.4441e+08                 3.28139e+08    7849.84  81.4616\n",
      "       0.329848                   3.10113e+08                2.45927e+08    2679.83  26.2907\n",
      "       0.30996                    4.59511e+08                1.41421e+08    8884.83  78.6893\n",
      "       0.304959                   2.39948e+08                1.54919e+08    1774.99  16.9706\n",
      "       0.293496                   6.22495e+08                4.12492e+08    2855     38.4968\n",
      "       0.289957                   8.87694e+08                6.43972e+08    7849.84  82.4621\n",
      "       0.289957                   4.47744e+08                2.83417e+08    7849.84  81.4616\n",
      "       0.285657                   8.5577e+08                 3.98008e+08    8442.26  83.051\n",
      "       0.329903                   2.51714e+08                1.71785e+08    2878.85  25.1929\n",
      "       0.316263                   1.16997e+09                1.05131e+09    4650.17  42.0381\n",
      "       0.359861                   1.16482e+09                1.03764e+09    4599.99  44.2719\n",
      "       0.329903                   3.25131e+08                1.49812e+08    2739.87  26.6908\n",
      "       0.275455                   1.37722e+09                1.23214e+09    7805.63  78.9497\n",
      "       0.269954                   5.8292e+08                 3.09354e+08    7749.84  75.9737\n",
      "       0.316263                   1.11716e+09                1.0317e+09     4539.45  44.0888\n",
      "       0.303974                   2.5838e+08                 2.5838e+08     1843.91   9.53205\n",
      "       0.329903                   3.61839e+08                2.9563e+08     2712.87  27.091\n",
      "       0.336667                   3.92161e+08                2.92506e+08    2767.96  28.709\n",
      "       0.289957                   7.75887e+08                5.89194e+08    7849.84  82.4621\n",
      "       0.293998                   6.22495e+08                5.02494e+08    2855     38.4968\n",
      "       0.316263                   1.0317e+09                 9.61969e+08    4539.45  44.0888\n",
      "       0.275455                   1.27137e+09                9.61381e+08    7916.35  73.8231\n",
      "       0.289957                   9.02774e+08                5.66833e+08    7849.84  81.9451\n",
      "       0.294618                   1.2276e+09                 8.05528e+08    8199.39  84.8528\n",
      "       0.336667                   2.60726e+08                1.75186e+08    2684.92  27.6837\n",
      "       0.275455                   1.23214e+09                1.12386e+09    7805.63  78.9497\n",
      "       0.269954                   5.49731e+08                2.8931e+08     7749.84  75.9737\n",
      "       0.306061                   1.70313e+09                1.55805e+09    7833.31  78.9497\n",
      "       0.275455                   1.22876e+09                1.04794e+09    8248.51  51.266\n",
      "       0.284605                   1.3025e+09                 8.35688e+08    8024.65  87.178\n",
      "       0.346869                   3.64736e+08                2.88229e+08    4511.77  46.1394\n",
      "       0.275455                   1.20263e+09                9.27513e+08    7916.35  73.8231\n",
      "       0.279285                   7.62496e+08                5.5491e+08     2874.89  62.8013\n",
      "       0.289957                   6.51767e+08                4.79635e+08    7849.84  80.4239\n",
      "       0.336667                   4.88283e+08                4.22294e+08    2795.64  27.6837\n",
      "       0.289957                   6.66333e+08                5.14296e+08    7849.84  82.4621\n",
      "       0.357071                   1.88185e+08                1.27209e+08    1815.78  17.4304\n"
     ]
    }
   ],
   "source": [
    "#\"\"\"Confirm features\"\"\"\n",
    "#print(type(features_test[0]))\n",
    "#print(features_test[0])\n",
    "table = []\n",
    "for mt in mts_test:\n",
    "    table.append([mt['Poisson_ratio'], mt['Tensile_strength,_ultimate'],mt['Tensile_strength,_yield'],mt['Density'],get_targets_mine(mt)])\n",
    "\n",
    "print(tabulate.tabulate(table, headers=['Poisson_ratio','Tensile_strength,_ultimate', 'Tensile_strength,_yield', 'Density', 'Target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"Feature Scaling/Preprocessing.\"\"\"\n",
    "np.set_printoptions(threshold=1000000000)\n",
    "scaler = StandardScaler() \n",
    "#scaler = RobustScaler()\n",
    "scaler.fit(features_train)# Do remember learn from training set ONLY.\n",
    "\n",
    "#\"\"\"Scale all the features.\"\"\"\n",
    "features_train = scaler.transform(features_train)\n",
    "features_test  = scaler.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fitting (training) model(s).\"\"\"\n",
    "Train_MAE = []\n",
    "Test_MAE = []\n",
    "Train_Pearson_r =[]\n",
    "Test_Pearson_r = []\n",
    "for HL in range(19,20): #(19,20)\n",
    "    models = []\n",
    "    \"\"\"Build a neural network model\"\"\"\n",
    "    layers = (HL,HL,HL,HL,HL,) #(HL,HL,HL,HL,HL,)\n",
    "    act_func = 'relu'#'tanh'#'identity''logistic'\n",
    "    if (len(mts_train) < 10000):\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=layers, solver='lbfgs', activation=act_func, max_iter=100000, tol=1e-6,early_stopping=True,verbose = False)\n",
    "    else:\n",
    "        mlp = MLPRegressor(hidden_layer_sizes=layers, solver='adam', activation=act_func, max_iter=10000, tol=1e-6)\n",
    "    mlp.fit(features_train, targets_train)\n",
    "    models.append(mlp)\n",
    "    print('MLP with solver: {}'.format(mlp.solver))\n",
    "    print(\"# of MLP iterations: {}\".format(mlp.n_iter_))\n",
    "    \n",
    "    \"\"\"Collecting data for better arrangement.\"\"\"\n",
    "    training_set = aggregate_data(mts_train, features_train, targets_train)\n",
    "    testing_set  = aggregate_data(mts_test, features_test, targets_test)\n",
    "    \n",
    "    \"\"\"Evaluation the results.\"\"\"\n",
    "    estimators = []\n",
    "    estimators.append({'name':'{}'.format('MLP -     '), 'regressor':models[0]})\n",
    "    print('\\nResults of Training')    \n",
    "    show_correlations(estimators, features_train, targets_train)\n",
    "    \n",
    "    \"\"\"Cross validation.\"\"\"\n",
    "    k_fold = 10\n",
    "    scores = []\n",
    "    print('\\n============= {}-Fold Cross Validation on Training Set =========='.format(k_fold))\n",
    "    for estimator in estimators:\n",
    "        score = cross_val_score(estimator['regressor'], features_train, targets_train, cv=k_fold)\n",
    "        scores.append(score)\n",
    "        print(\"{}: score = {} +- {}\".format(estimator['name'], score.mean(), score.std()*2))\n",
    "        display_cv(scores)\n",
    "        print('\\nResults of Testing')  \n",
    "        show_correlations(estimators, features_test, targets_test)\n",
    "        # show_elements_on_ptable([mts_test, mts_train])\n",
    "    \"\"\"Visualize the results.\"\"\"\n",
    "    for estimator in estimators:\n",
    "    #    plot_regression_results(training_set, testing_set, estimator, print_details=True)\n",
    "        def data4plotly_v2(training_set, testing_set, predictor):\n",
    "            \"\"\"Return python dicts(of training and testing set) for further plotly processing.\"\"\"\n",
    "            training_dict = dict()\n",
    "            testing_dict  = dict()\n",
    "            \"\"\"Put the training set in to proper format\"\"\"\n",
    "            training_dict['real']    = training_set['target']\n",
    "            training_dict['predict'] = predictor.predict(training_set['feature'])\n",
    "            training_dict['tag']     = [\"Pretty:{}, Full:{}\".format(mt['pretty_formula'], mt['full_formula']) for mt in training_set['mt']]\n",
    "            \"\"\"Put the training set in to proper format.\"\"\"\n",
    "            testing_dict['real']    = testing_set['target']\n",
    "            testing_dict['predict'] = predictor.predict(testing_set['feature'])\n",
    "            testing_dict['tag']     = [\"Pretty:{}, Full:{}\".format(mt['pretty_formula'], mt['full_formula']) for mt in testing_set['mt']]\n",
    "            return training_dict, testing_dict\n",
    "    \n",
    "        def plot_regression_results_v2(training_set, testing_set, regressor, print_details = True):\n",
    "            \"\"\"Plot the regression results of training set, testing set.\"\"\"\n",
    "            def mae(v1, v2):\n",
    "                \"\"\"Return the MAE (mean absolute error) of v1 & v2.\"\"\"\n",
    "                return mean(abs((v1 - v2)/v2))*100\n",
    "#    predicts_train = training_set['target'] - regressor['regressor'].predict(training_set['feature'])\n",
    "#    predicts_test  = testing_set['target']  - regressor['regressor'].predict(testing_set['feature'])\n",
    "            training, testing = data4plotly(training_set, testing_set, regressor['regressor'])\n",
    "    \n",
    "            if print_details:\n",
    "                \"\"\"export data\"\"\"\n",
    "                print(\"{} Regressor\".format(regressor['name']))\n",
    "                print('Train - MAE: {}'.format(round(mae(training_set['target'], training['predict']),4)))\n",
    "                print('Test  - MAE: {}'.format(round(mae(testing_set['target'], testing['predict']),4)))\n",
    "                pearson_training=pearsonr(training_set['target'],training['predict'])\n",
    "                print('Train - Pearson r: {},{}'.format(round(pearson_training[0],4),round(pearson_training[1],4)))\n",
    "                #print('Train - Pearson r: {}'.format(pearsonr(training_set['target'], training['predict'])))\n",
    "                pearson_testing=pearsonr(testing_set['target'],testing['predict'])\n",
    "                print('Test  - Pearson r: {},{}'.format(round(pearson_testing[0],4),round(pearson_testing[1],4)))\n",
    "                #print('Test  - Pearson r: {}'.format(pearsonr(testing_set['target'], testing['predict'])))\n",
    "                Train_MAE.append(mae(training_set['target'], training['predict']))\n",
    "                Test_MAE.append(mae(testing_set['target'], testing['predict']))\n",
    "                Train_Pearson_r.append(pearsonr(training_set['target'], training['predict']))\n",
    "                Test_Pearson_r.append(pearsonr(testing_set['target'], testing['predict']))\n",
    "                \n",
    "                \"\"\"Loss Function\"\"\"\n",
    "                #for i in range(1,(mlp.n_iter_)+1):\n",
    "                    #print(mlp.loss_)\n",
    "                    #print(i)\n",
    "                \n",
    "                \"\"\"Plot Text\"\"\"\n",
    "                Xorigin_pt = max(training['real'] + testing['real'])\n",
    "                #if min(training['real']) < min(testing['real']) and min(training['real'])<min(training['predict']) and min(training['real'])<min(testing['predict']):\n",
    "                    #Yorigin_pt = min(training['real'])\n",
    "                #elif min(training['predict'])<min(training['real']) and min(training['predict'])<min(testing['real']) and min(training['predict'])<min(testing['predict']):\n",
    "                    #Yorigin_pt = min(training['predict'])\n",
    "                #elif min(testing['predict'])<min(training['predict']) and min(testing['predict'])<min(testing['real']) and min(testing['predict'])<min(training['predict']):\n",
    "                    #Yorigin_pt = min(testing['predict'])\n",
    "                #else:\n",
    "                    #Yorigin_pt = min(testing['real'])\n",
    "                plt.figure(figsize=(10, 10))\n",
    "                #plt.text(Xorigin_pt-60,25,\"{} Regressor\".format(regressor['name']))\n",
    "                #plt.text(Xorigin_pt-60,20,'Train - MAE: {}'.format(round(mae(training_set['target'], training['predict']),4)))\n",
    "                #plt.text(Xorigin_pt-60,15,'Test  - MAE: {}'.format(round(mae(testing_set['target'], testing['predict']),4)))\n",
    "                plt.text(Xorigin_pt-53.5,8,'Train - Pearson r: {},{}'.format(round(pearson_training[0],4),round(pearson_training[1],4)),size=15)\n",
    "                plt.text(Xorigin_pt-53.5,3,'Test  - Pearson r: {},{}'.format(round(pearson_testing[0],4),round(pearson_testing[1],4)),size=15)\n",
    "                \n",
    "                training, testing = data4plotly_v2(training_set, testing_set, regressor['regressor'])\n",
    "                plotly_pairing_set_v2(training, testing)\n",
    "                \n",
    "        def plotly_pairing_set_v2(training, testing):\n",
    "            \"\"\"Plot the training & testing sets.\"\"\"\n",
    "            Scatter1 = plt.scatter(training['real'],\n",
    "                                   training['predict'],\n",
    "                                   edgecolors='b',\n",
    "                                   marker='s',\n",
    "                                   facecolors='none'\n",
    "                                   )\n",
    "\n",
    "            Scatter2 =  plt.scatter(testing['real'],\n",
    "                                    testing['predict'],\n",
    "                                    edgecolors='r',\n",
    "                                    marker='o',\n",
    "                                    facecolors='none')\n",
    "        \n",
    "            \"\"\"Ideal Curve\"\"\"\n",
    "            end_pt = max(training['real'] + testing['real'])\n",
    "            left_point = [0,end_pt]\n",
    "            right_point = [0,end_pt]\n",
    "            line, = plt.plot(left_point, right_point, 'g-')\n",
    "\n",
    "\n",
    "            \"\"\"Plot Details\"\"\"\n",
    "            legendsize = {'size': 15}\n",
    "            legend1 = '{}_Training Set'.format(MyTarget)\n",
    "            legend2 = '{}_Testing Set'.format(MyTarget)\n",
    "            plt.legend((Scatter1,Scatter2,line,),(legend1,legend2,'r = 1.0'),loc =2, prop=legendsize)\n",
    "            #plt.title('Plot [Real] v.s. [Predict]')\n",
    "            plt.xlabel('Real*(10^9) ',size=20)   # nm,μm,mm,cm,m \n",
    "            plt.ylabel('Predict*(10^9) ',size=20)  # nm,μm,mm,cm,m  \n",
    "            #plt.xlabel('Real*{}'.format(units))\n",
    "            #plt.ylabel('Predict*{}'.format(units))\n",
    "            ax=plt.gca()\n",
    "            for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "                label.set_fontsize(20)\n",
    "                label.set_bbox(dict(facecolor='w',edgecolor='None',alpha=0.4))\n",
    "            ax.spines['bottom'].set_linewidth(3)\n",
    "            ax.spines['top'].set_linewidth(3)\n",
    "            ax.spines['left'].set_linewidth(3)\n",
    "            ax.spines['right'].set_linewidth(3)\n",
    "            tick_params(which='major',length = 6,width=2)\n",
    "            plt.xlim(0, end_pt+3)\n",
    "            plt.ylim(0, end_pt+3)\n",
    "            #plt.show()\n",
    "            plt.savefig('{}_{}'.format(MyTarget,layers), dpi=600 )\n",
    "            plt.cla()\n",
    "        plot_regression_results_v2(training_set, testing_set, estimator, print_details=True)\n",
    "    #print(HL)\n",
    "    #print(layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Export Data\"\"\"    \n",
    "#print(Train_MAE)\n",
    "#print(Test_MAE)\n",
    "#print(Train_Pearson_r)\n",
    "#print(Test_Pearson_r)\n",
    "Train_Pearson_r_need,Train_Pearson_r_no = zip(*Train_Pearson_r)\n",
    "Test_Pearson_r_need,Test_Pearson_r_no = zip(*Test_Pearson_r)\n",
    "d = {'Train_MAE':Train_MAE, \n",
    "     'Test_MAE':Test_MAE,\n",
    "     'Train_Pearson_r_need':Train_Pearson_r_need,\n",
    "     'Train_Pearson_r_no':Train_Pearson_r_no,\n",
    "     'Test_Pearson_r_need':Test_Pearson_r_need,\n",
    "     'Test_Pearson_r_no':Test_Pearson_r_no\n",
    "     }\n",
    "df = pd.DataFrame(data = d)\n",
    "#print(df)\n",
    "np.savetxt('ML_{}_{}layers.txt'.format(MyTarget,len(layers)), df)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
